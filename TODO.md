

# ToDo list

- [x] Update [requirements.txt](./requirements.txt)
- [ ] Design the architecture of code
- [x] Choice test tool and init them
- [ ] Choice docs tool and init this 
- [ ] Config codecov
- [x] Config codefactor
- [ ] Create Code style standard and document it in [CONTRIBUTING.md](./CONTRIBUTING.md)
- [ ] List Agents for starting project
- [ ] List Environments for start project

# Agents list

- [ ] Random Agent
- [ ] Deep Q Network (Mnih *et al.*, [2013](https://arxiv.org/abs/1312.5602))
- [ ] Deep Recurrent Q Network (Hausknecht *et al.*, [2015](https://arxiv.org/abs/1507.06527))
- [ ] Persistent Advantage Learning (Bellamare *et al.*, [2015](https://arxiv.org/abs/1512.04860))
- [ ] Double Deep Q Network (van Hasselt *et al.*, [2016](https://arxiv.org/abs/1509.06461))
- [ ] Dueling Q Network (Wang *et al.*, [2016](https://arxiv.org/abs/1511.06581))
- [ ] Bootstraped Deep Q Network (Osband *et al.*, [2016](https://arxiv.org/abs/1602.04621))
- [ ] Continuous Deep Q Network (Gu*et al.*, [2016](https://arxiv.org/abs/1603.00748))
- [ ] C51 = Distributed Deep Q Network (Bellamare *et al.*, [2017](https://arxiv.org/abs/1707.06887))
- [ ] Rainbow (Hessel *et al.*, [2017](https://arxiv.org/abs/1710.02298))
- [ ] Quantile Regression Deep Q Network (Dabney *et al.*, [2017](https://arxiv.org/abs/1710.10044))
- [ ] Proximal Policy Optimizations (Schulman *et al.*, [2017](https://arxiv.org/abs/1707.06347))

# Explorations list

- [ ] Random
- [ ] Epsilon Greedy
- [ ] Intrinsic Curiosity Module (Pathak *et al.*, [2017](https://arxiv.org/abs/1705.05363))
- [ ] Random Network Distillation (Burda *et al.*, [2017](https://arxiv.org/abs/1810.12894))

# Memories list

- [ ] Prioritized Experience Replay (Schaul *et al.*, [2015](https://arxiv.org/abs/1511.05952))
- [ ] Hindsight Experience Replay (Andrychowicz *et al.*, [2017](https://arxiv.org/abs/1707.01495))

# Environments list

- [ ] Gym CartPole
